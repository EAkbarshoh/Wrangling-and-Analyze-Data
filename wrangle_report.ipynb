{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wrangle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I conducted this Data wrangling project in 3 big steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step(Gathering)\n",
    "In the first step I gathered data from various recouses in different ways.To be precise,\n",
    "- Firstly I downloaded data manualy(twitter_archive_enhanced.csv),It was provided by Udacity\n",
    "- Then I downloaded data programmaticaly (image_predictions.tsv) with help of modul called `requests`,there was link to download it.This data was about breeds of dogs (predicted by neural network)\n",
    "- Finally I used Tweepy to use API of Twitter to get data.First I got list of tweet_ids from (twitter_archive_enhanced.csv),then I used these ids to get JSONs after storing all of them  in text (each in one line),I read this `txt` file line by line and appended data to list in order to make dataframe from it\n",
    "\n",
    "The reason why I also downloaded programmaticaly is that when someone else is going to see my analysis,he or she can jus t open my Jupyter notebook re-run cells and when I try to conduct this analysis again but with updated data, I can also re-run these cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step(Assessing)\n",
    "In the second step,I assessed data both programmaticaly and visually.For Visial assessment,I used exteranl application`Excel` as it is not comfortable to use pandas for this case.For programmatic assessment,I used Pandas itself,methods `.info`,`.describe`, and other features like filtering.After finding issuse,I separated them into to groups Quality issue and Tidiness issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step(Cleaning)\n",
    "First thing I did in this step was getting copies of three gathered dataframes so that if I do mistake,It will not affect to orginal data.when ever I make mistake,I could re-copy dataframes and continue cleaning\n",
    "I divided cleaning each issue into three parts,define,code ,test.\n",
    "There was several challenging steps.First was in prediction table.There were 3 predictions of neural network(some of them was not breed of dogs).I got only one prediction which is breed of dog and with high confidence level.Another one was dog's stages in four columns,I used melt function to solve this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Data wrangling is important skill which every data analayst should have,as it takes much time and without it we can not do any analysis.Even If we do,I wil lead to wrong results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
